{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils.get_datasets as get_datasets\n",
    "import utils.config as config\n",
    "import models.arch as arch\n",
    "import models.get_loss_optim as get_loss_optim\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch\n",
    "from torch import nn, optim \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       icd_code  icd_version  \\\n",
      "0          0010            9   \n",
      "1          0011            9   \n",
      "2          0019            9   \n",
      "3          0020            9   \n",
      "4          0021            9   \n",
      "...         ...          ...   \n",
      "109770     Z992           10   \n",
      "109771     Z993           10   \n",
      "109772     Z998           10   \n",
      "109773    Z9981           10   \n",
      "109774    Z9989           10   \n",
      "\n",
      "                                               long_title  \n",
      "0                          Cholera due to vibrio cholerae  \n",
      "1                   Cholera due to vibrio cholerae el tor  \n",
      "2                                    Cholera, unspecified  \n",
      "3                                           Typhoid fever  \n",
      "4                                     Paratyphoid fever A  \n",
      "...                                                   ...  \n",
      "109770                       Dependence on renal dialysis  \n",
      "109771                           Dependence on wheelchair  \n",
      "109772  Dependence on other enabling machines and devices  \n",
      "109773                  Dependence on supplemental oxygen  \n",
      "109774  Dependence on other enabling machines and devices  \n",
      "\n",
      "[109775 rows x 3 columns]          subject_id   hadm_id  seq_num icd_code  icd_version\n",
      "0          10000032  22595853        1     5723            9\n",
      "1          10000032  22595853        2    78959            9\n",
      "2          10000032  22595853        3     5715            9\n",
      "3          10000032  22595853        4    07070            9\n",
      "4          10000032  22595853        5      496            9\n",
      "...             ...       ...      ...      ...          ...\n",
      "4756321    19999987  23865745        7    41401            9\n",
      "4756322    19999987  23865745        8    78039            9\n",
      "4756323    19999987  23865745        9     0413            9\n",
      "4756324    19999987  23865745       10    36846            9\n",
      "4756325    19999987  23865745       11     7810            9\n",
      "\n",
      "[4756326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# how to get files\n",
    "# icustays = get_icu_files('icustays.csv.gz')\n",
    "d_icd_diagnoses = get_datasets.get_hosp_files('d_icd_diagnoses.csv.gz')\n",
    "icd_diagnoses = get_datasets.get_hosp_files('diagnoses_icd.csv.gz')\n",
    "\n",
    "print(d_icd_diagnoses, icd_diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         subject_id   hadm_id  seq_num icd_code  icd_version_x  icd_version_y  \\\n",
      "0          10000032  22595853        1     5723              9              9   \n",
      "1          10000826  20032235        4     5723              9              9   \n",
      "2          10000826  28289260        1     5723              9              9   \n",
      "3          10005866  26158160        4     5723              9              9   \n",
      "4          10008924  23676183        7     5723              9              9   \n",
      "...             ...       ...      ...      ...            ...            ...   \n",
      "4860275    19990427  29695607       24  T24011A             10             10   \n",
      "4860276    19996016  28015466        4   O30093             10             10   \n",
      "4860277    19996783  25894657       20  H353131             10             10   \n",
      "4860278    19997062  20096107        1    K8036             10             10   \n",
      "4860279    19999043  23037011       10  O359XX2             10             10   \n",
      "\n",
      "                                                long_title  \n",
      "0                                      Portal hypertension  \n",
      "1                                      Portal hypertension  \n",
      "2                                      Portal hypertension  \n",
      "3                                      Portal hypertension  \n",
      "4                                      Portal hypertension  \n",
      "...                                                    ...  \n",
      "4860275  Burn of unspecified degree of right thigh, ini...  \n",
      "4860276  Twin pregnancy, unable to determine number of ...  \n",
      "4860277  Nonexudative age-related macular degeneration,...  \n",
      "4860278  Calculus of bile duct with acute and chronic c...  \n",
      "4860279  Maternal care for (suspected) fetal abnormalit...  \n",
      "\n",
      "[4860280 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# how to join dataframe\n",
    "# example - inner join with icd_code (hosp_data)\n",
    "new_df = pd.merge(left=icd_diagnoses, right=d_icd_diagnoses, how='inner', on='icd_code')\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 0, 'seed': 42, 'model': 'SVM', 'batch_size': 128, 'num_workers': 2, 'epoch': 200, 'num_cls': 100, 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': True, 'data_path': './', 'save_path': './', 'print_freq': 10}\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# get arguments ( utils / config.py)\n",
    "args = config.get_arguments()\n",
    "print(args)\n",
    "# gpu setup\n",
    "device = config.setup(args)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# 데이터 전처리 이후 학습 Feature와 target Feature 설정해야함.\n",
    "data = new_df['subject_id']\n",
    "target = new_df['icd_code']\n",
    "\n",
    "# train : test = 8 : 2  -> split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True, stratify=target, random_state=args.seed)\n",
    "\n",
    "# if use torch models\n",
    "'''\n",
    "trainset = TensorData(x_train, y_train)\n",
    "testset = TensorData(x_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbregressor example\n",
    "\n",
    "import xgboost as XGBRegressor\n",
    "\n",
    "# use xgboost\n",
    "model = XGBRegressor()\n",
    "models = []\n",
    "\n",
    "kfold = KFold(n_splits=args.folds, shuffle=True)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train)):\n",
    "    # use xgboost\n",
    "    x_t = x_train.iloc[train_idx]\n",
    "    y_t = y_train.iloc[train_idx]\n",
    "    x_val = x_train.iloc[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "\n",
    "    models.append(model.fit(x_t, y_t),\n",
    "                  eval_set = [(x_val, y_val)],\n",
    "                  early_stopping_rounds = 100,\n",
    "                  verbose=100)\n",
    "\n",
    "    # use sampler if use torchmodels\n",
    "    '''\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, sampler=train_subsampler) # 해당하는 index 추출\n",
    "    valloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, sampler=val_subsampler)\n",
    "    '''\n",
    "\n",
    "    # get model to models/arch.py\n",
    "    '''\n",
    "    model = arch.get_model(args)\n",
    "    optimizer, criterion = get_loss_optim.get_optimizer(args, model)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        valloss = 0\n",
    "        trainloss = 0\n",
    "\n",
    "        model.train()\n",
    "        for data in tqdm.tqdm(trainloader):\n",
    "            inputs, values = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, values)\n",
    "            trainloss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm.tqdm(valloader):\n",
    "                inputs, values = data\n",
    "                outputs = model(inputs)\n",
    "                valloss += criterion(outputs, values)\n",
    "\n",
    "    print(\"k-fold\", fold,\" Train Loss: %.4f, Validation Loss: %.4f\" %(trainloss/len(trainloader), valloss/len(valloader))) \n",
    "    '''\n",
    "\n",
    "# xgboost prediction\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(model.predict(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
